{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TF\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from conf import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(origin_text):\n",
    "    # 去掉html标签\n",
    "    text = BeautifulSoup(origin_text).get_text()\n",
    "    # 去掉标点符号和非法字符\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # 将字符全部转化为小写，并通过空格符进行分词处理\n",
    "    words = text.lower().split()\n",
    "    # 去停用词\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if w not in stop_words]\n",
    "    # 将剩下的词还原成str类型\n",
    "    cleaned_text = \" \".join(meaningful_words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ü collecting ur laptop then going to configure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I can't text &amp;amp; drive coherently, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for shows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>What's up. Do you want me to come online?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Ü collecting ur laptop then going to configure...\n",
       "1   ham  Sorry, I can't text &amp; drive coherently, se...\n",
       "2  spam  PRIVATE! Your 2003 Account Statement for shows...\n",
       "3   ham          What's up. Do you want me to come online?\n",
       "4   ham  The guy did some bitching but I acted like i'd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv(config.train_path)\n",
    "# test = pd.read_csv(config.test_path)\n",
    "train = pd.read_csv(config.origin_train_path, sep='\\t', header=None, names=['label', 'text'])\n",
    "test = pd.read_csv(config.origin_test_path, sep='\\t', header=None, names=['text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: clean_text(x))\n",
    "test['text'] = test['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    collecting ur laptop going configure da settin...\n",
       "1               sorry text drive coherently see twenty\n",
       "2    private account statement shows un redeemed po...\n",
       "3                                     want come online\n",
       "4    guy bitching acted like interested buying some...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the tfidf vector...\n",
      "\n",
      "(3448, 5000)\n",
      "(1672, 5000)\n"
     ]
    }
   ],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "tfidf = TF(analyzer=\"word\",\n",
    "           tokenizer=None,\n",
    "           preprocessor=None,\n",
    "           stop_words=None,\n",
    "           max_features=5000)\n",
    "\n",
    "# 数据向量化\n",
    "print(\"Creating the tfidf vector...\\n\")\n",
    "tfidf.fit(train['text'])\n",
    "x_train = tfidf.transform(train['text'])\n",
    "x_train = x_train.toarray()\n",
    "\n",
    "x_test = tfidf.transform(test['text'])\n",
    "x_test = x_test.toarray()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"]\n",
    "# x_train, x_val, y_train, y_cal = train_test_split(x_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ham': 3041, 'spam': 407})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ham': 3041, 'spam': 3041})\n"
     ]
    }
   ],
   "source": [
    "smo = SMOTE(random_state=0)\n",
    "x_smo, y_smo = smo.fit_sample(x_train, y_train)\n",
    "print(Counter(y_smo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR(solver='liblinear')\n",
    "# model.fit(x_train, y_train)\n",
    "model.fit(x_smo, y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10折交叉验证：\n",
      "0.9843684943785643\n"
     ]
    }
   ],
   "source": [
    "print(\"10折交叉验证：\")\n",
    "# print(np.mean(cross_val_score(model, x_train, train[\"sentiment\"], cv=10, scoring=\"accuracy\")))\n",
    "print(np.mean(cross_val_score(model, x_train, y_train, cv=10, scoring=\"roc_auc\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id pred\n",
       "0   1  ham\n",
       "1   2  ham\n",
       "2   3  ham\n",
       "3   4  ham\n",
       "4   5  ham"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "submission = pd.DataFrame({'id': range(len(preds)), 'pred': preds})\n",
    "submission['id'] = submission['id'] + 1\n",
    "submission.to_csv(\"../data/ml_submission.csv\", index=False, header=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "answer = pd.read_csv('../data/origin_data/answer.csv')\n",
    "print('%.2f' % (accuracy_score(answer.label, submission.pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
